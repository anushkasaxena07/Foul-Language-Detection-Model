{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e208e4d",
   "metadata": {},
   "source": [
    "# Foul Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "324b99e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Assuming cv is your CountVectorizer instance\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Load foul_detector_model with try-except block\n",
    "try:\n",
    "    md = joblib.load(\"foul_detector_model.joblib\")\n",
    "    \n",
    "    # Get the absolute path to the current directory\n",
    "    current_directory = os.path.abspath(os.getcwd())\n",
    "    \n",
    "    # Construct the absolute path to the vocabulary file\n",
    "    vocabulary_path = os.path.join(current_directory, \"vocabulary.joblib\")\n",
    "    \n",
    "    # Check if the vocabulary file exists before loading\n",
    "    if os.path.exists(vocabulary_path):\n",
    "        # Load the vocabulary\n",
    "        vocabulary = joblib.load(vocabulary_path)\n",
    "        \n",
    "        # Set the vocabulary for CountVectorizer\n",
    "        cv.vocabulary_ = vocabulary\n",
    "    else:\n",
    "        print(\"Vocabulary file not found.\")\n",
    "    \n",
    "except (ValueError, KeyError) as e:\n",
    "    print(f\"Error loading the model or vocabulary: {e}\")\n",
    "    # Additional troubleshooting or fallback action may be needed here\n",
    "    # You might want to retrain and save the model if there are no compatibility issues\n",
    "\n",
    "def detect(test_data):\n",
    "    # Assuming the model was trained with the same CountVectorizer instance\n",
    "    df = cv.transform([test_data]).toarray()\n",
    "    m = int(md.predict(df))\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740ee34",
   "metadata": {},
   "source": [
    "# Voice detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcc84adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\braje\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e158db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from audio data\n",
    "def extract_features(file_path):\n",
    "    audio_data, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
    "    return np.mean(mfccs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a83f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\braje\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\braje\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = models.load_model('speaker_identification_model.h5')\n",
    "\n",
    "# Load the label encoder\n",
    "loaded_label_encoder = LabelEncoder()\n",
    "loaded_label_encoder.classes_ = np.load('label_encoder.npy')\n",
    "\n",
    "def Recog_voice(new_audio_file_wav):\n",
    "    # Example: Get predictions for a new WAV audio file\n",
    "    #new_audio_file_wav = 'd_v.wav'\n",
    "    new_features_wav = extract_features(new_audio_file_wav)\n",
    "\n",
    "    # Reshape the input data to match the model's input shape\n",
    "    new_features_reshaped_wav = new_features_wav.reshape(1, len(new_features_wav), 1)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_wav = loaded_model.predict(new_features_reshaped_wav)  # Use loaded_model instead of model\n",
    "\n",
    "    # Get the index with the highest predicted value\n",
    "    predicted_index_wav = np.argmax(predictions_wav)\n",
    "\n",
    "    # Decode the predicted labels using the loaded label encoder\n",
    "    predicted_label_wav = loaded_label_encoder.inverse_transform(np.array([predicted_index_wav])).reshape(1, -1)\n",
    "\n",
    "    print(f'Predicted Speaker: {predicted_label_wav[0]}')\n",
    "    return predicted_label_wav[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb25b069",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d8ee0ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 52\u001b[0m\n\u001b[0;32m     48\u001b[0m dashboard \u001b[38;5;241m=\u001b[39m Dashboard(save_folder\u001b[38;5;241m=\u001b[39mcustom_folder_path)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m dashboard\u001b[38;5;241m.\u001b[39mconvert_audio_to_text()\n\u001b[0;32m     54\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m get_time()\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Capture the returned audio file path\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 22\u001b[0m, in \u001b[0;36mDashboard.convert_audio_to_text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_audio_to_text\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Generate a timestamp for the filename\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m get_time()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Specify the folder path to save the audio file\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     audio_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_input_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_time' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "from datetime import datetime\n",
    "\n",
    "class Dashboard:\n",
    "    uniquecode=1\n",
    "    \n",
    "    def __init__(self, save_folder=\"audio_inputs\"):\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.microphone = sr.Microphone()\n",
    "        self.save_folder = save_folder\n",
    "\n",
    "        # Ensure the specified folder exists; create it if not\n",
    "        os.makedirs(self.save_folder, exist_ok=True)\n",
    "   \n",
    "    def convert_audio_to_text(self):\n",
    "        # Generate a timestamp for the filename\n",
    "        global uniquecode  # Use the global variable\n",
    "        current_uniquecode = uniquecode  # Store the current value\n",
    "        uniquecode += 1  # Increment the global value\n",
    "        \n",
    "        # Specify the folder path to save the audio file\n",
    "        audio_file_path = os.path.join(self.save_folder, f\"audio_input_{current_uniquecode}.wav\")\n",
    "\n",
    "        with self.microphone as source:\n",
    "            print(\"Listening...\")\n",
    "            try:\n",
    "                audio_data = self.recognizer.listen(source, timeout=5)  # Adjust timeout as needed\n",
    "                # Save the audio data to a file\n",
    "                with open(audio_file_path, \"wb\") as audio_file:\n",
    "                    audio_file.write(audio_data.get_wav_data())\n",
    "\n",
    "                text = self.recognizer.recognize_google(audio_data)\n",
    "                return text\n",
    "            except sr.UnknownValueError:\n",
    "                return \"Could not understand audio\"\n",
    "            except sr.RequestError as e:\n",
    "                return f\"Error connecting to Google API: {e}\"\n",
    "\n",
    "    Dashboard.uniquecode +=1\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the custom folder path (replace 'your_custom_folder' with the desired folder name)\n",
    "    custom_folder_path = \"audio_inputs\"\n",
    "\n",
    "    # Create an instance of Dashboard with the custom folder path\n",
    "    dashboard = Dashboard(save_folder=custom_folder_path)\n",
    "\n",
    "    \n",
    "    # Example usage:\n",
    "    result = dashboard.convert_audio_to_text()\n",
    "    \n",
    "    # Capture the returned audio file path\n",
    "    audio_file_path = os.path.join(dashboard.save_folder, f\"audio_input_{Dashboard.uniquecode}.wav\")\n",
    "\n",
    "    print(\"Text from audio:\")\n",
    "    output = detect(result)\n",
    "    print(result)\n",
    "    print(output)\n",
    "    \n",
    "    # Pass the captured audio file path to Recog_voice\n",
    "    S_name=Recog_voice(audio_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f731a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "860ed765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240123_1942'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25142265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ce553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc1f89c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection_cext.CMySQLConnection object at 0x000001FD8DFB9110>\n"
     ]
    }
   ],
   "source": [
    "# Database \n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "    host =\"localhost\",\n",
    "    user =\"root\",\n",
    "    password =\"8871@Ajay\",\n",
    "    database = \"Foul_DB\"\n",
    ")\n",
    "\n",
    "print(mydb)\n",
    "cur = mydb.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9566832c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import librosa\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "\n",
    "# cur.execute(\"CREATE TABLE Students (id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255) NOT NULL)\")\n",
    "\n",
    "#cur.execute(\"CREATE TABLE Defaulters_list (ID INT PRIMARY KEY, audio VARCHAR(255) NOT NULL, fine DECIMAL(10, 2) NOT NULL, FOREIGN KEY (ID) REFERENCES Students(id))\")\n",
    "\n",
    "# Uncomment the next line if you're inserting data into the Students table\n",
    "# cur.execute(\"INSERT INTO Students (name) VALUES ('Kratika')\")\n",
    "\n",
    "\n",
    "# Execute the SELECT query\n",
    "select_query = f\"SELECT id FROM Students WHERE name='{S_name[0]}'\"\n",
    "cur.execute(select_query)\n",
    "\n",
    "# Fetch the result\n",
    "result = cur.fetchone()\n",
    "\n",
    "# Check if result is not None\n",
    "if result:\n",
    "    student_id = result[0]\n",
    "    fine=100\n",
    "    # Use Binary class to handle binary data\n",
    "    insert_query = \"INSERT INTO Defaulters_list (ID,audio,fine) VALUES (%s, %s,%s)\"\n",
    "    cur.execute(insert_query, (student_id,audio_file_path,fine))\n",
    "\n",
    "    # Commit the changes\n",
    "    mydb.commit()\n",
    "else:\n",
    "    print(\"No student found with the given name.\")\n",
    "\n",
    "# Close the cursor\n",
    "cur.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a075981a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe6731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690b536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4328b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
