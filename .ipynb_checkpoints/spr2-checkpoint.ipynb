{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5411a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'resampy'\n\nThis error is lazily reported, having originally occured in\n  File C:\\Users\\braje\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py, line 32, in <module>\n\n----> resampy = lazy.load(\"resampy\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m dataset_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Collect data\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m X, y \u001b[38;5;241m=\u001b[39m collect_data(dataset_folder)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Encode labels\u001b[39;00m\n\u001b[0;32m     43\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "Cell \u001b[1;32mIn[19], line 30\u001b[0m, in \u001b[0;36mcollect_data\u001b[1;34m(dataset_folder)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     29\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(speaker_path, filename)\n\u001b[1;32m---> 30\u001b[0m     features \u001b[38;5;241m=\u001b[39m extract_features(file_path)\n\u001b[0;32m     31\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(features)\n\u001b[0;32m     32\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(speaker_folder)\n",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(file_path):\n\u001b[1;32m---> 14\u001b[0m     audio_data, sample_rate \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(file_path, res_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkaiser_fast\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m     mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39maudio_data, sr\u001b[38;5;241m=\u001b[39msample_rate, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(mfccs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:192\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    189\u001b[0m     y \u001b[38;5;241m=\u001b[39m to_mono(y)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     y \u001b[38;5;241m=\u001b[39m resample(y, orig_sr\u001b[38;5;241m=\u001b[39msr_native, target_sr\u001b[38;5;241m=\u001b[39msr, res_type\u001b[38;5;241m=\u001b[39mres_type)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     sr \u001b[38;5;241m=\u001b[39m sr_native\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:677\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[0m\n\u001b[0;32m    668\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\n\u001b[0;32m    669\u001b[0m         soxr\u001b[38;5;241m.\u001b[39mresample,\n\u001b[0;32m    670\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    674\u001b[0m         quality\u001b[38;5;241m=\u001b[39mres_type,\n\u001b[0;32m    675\u001b[0m     )\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 677\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m resampy\u001b[38;5;241m.\u001b[39mresample(y, orig_sr, target_sr, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39mres_type, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fix:\n\u001b[0;32m    680\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mfix_length(y_hat, size\u001b[38;5;241m=\u001b[39mn_samples, axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lazy_loader\\__init__.py:110\u001b[0m, in \u001b[0;36mDelayedImportErrorModule.__getattr__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__frame_data\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo module named \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspec\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis error is lazily reported, having originally occured in\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  File \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(fd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_context\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    115\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'resampy'\n\nThis error is lazily reported, having originally occured in\n  File C:\\Users\\braje\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py, line 32, in <module>\n\n----> resampy = lazy.load(\"resampy\")"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# pip install librosa scikit-learn soundfile\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Function to extract features from audio data\n",
    "def extract_features(file_path):\n",
    "    audio_data, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
    "    return np.mean(mfccs, axis=1)\n",
    "\n",
    "# Function to collect audio samples and labels from a dataset folder\n",
    "def collect_data(dataset_folder):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for speaker_folder in os.listdir(dataset_folder):\n",
    "        speaker_path = os.path.join(dataset_folder, speaker_folder)\n",
    "\n",
    "        if os.path.isdir(speaker_path):\n",
    "            for filename in os.listdir(speaker_path):\n",
    "                if filename.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(speaker_path, filename)\n",
    "                    features = extract_features(file_path)\n",
    "                    data.append(features)\n",
    "                    labels.append(speaker_folder)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Change the path to the folder where your dataset is stored\n",
    "dataset_folder = 'audio'\n",
    "\n",
    "# Collect data\n",
    "X, y = collect_data(dataset_folder)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Reshape((13, 1), input_shape=(13,)),\n",
    "    layers.Conv1D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[callbacks.EarlyStopping(patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Save the model\n",
    "model.save('speaker_identification_model.h5')\n",
    "\n",
    "# Save label encoder\n",
    "np.save('label_encoder.npy', label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822a08ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d587b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a77330f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715c171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "827b632c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braje\\anaconda3\\Lib\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=2\n",
      "  warnings.warn(\n",
      "C:\\Users\\braje\\anaconda3\\Lib\\site-packages\\librosa\\core\\spectrum.py:371: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  util.MAX_MEM_BLOCK // (np.prod(y_frames.shape[:-1]) * y_frames.itemsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.50%\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# pip install librosa scikit-learn soundfile SpeechRecognition\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import soundfile as sf\n",
    "import joblib\n",
    "\n",
    "# Function to extract features from audio data during training\n",
    "def extract_features(audio_data, sample_rate):\n",
    "    # Normalize the audio data to the range [0, 1]\n",
    "    audio_data_normalized = (audio_data - np.min(audio_data)) / (np.max(audio_data) - np.min(audio_data))\n",
    "\n",
    "    # Extract MFCC features\n",
    "    # Example with adjusted parameters\n",
    "    mfccs = librosa.feature.mfcc(y=audio_data_normalized, sr=sample_rate, n_mfcc=13, n_fft=1024, hop_length=512)\n",
    "\n",
    "    # Flatten MFCC features\n",
    "    features = mfccs.flatten()\n",
    "\n",
    "    # Ensure a consistent shape by padding if needed\n",
    "    max_feature_length = 12 * 13  # Adjust based on the actual feature dimensions\n",
    "    if len(features) < max_feature_length:\n",
    "        features = np.pad(features, (0, max_feature_length - len(features)), mode='constant', constant_values=(0, 0))\n",
    "    else:\n",
    "        features = features[:max_feature_length]\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to collect audio samples and labels from a dataset folder\n",
    "def generate_data(dataset_folder, chunk_size=10):\n",
    "    for speaker_folder in os.listdir(dataset_folder):\n",
    "        speaker_path = os.path.join(dataset_folder, speaker_folder)\n",
    "\n",
    "        if os.path.isdir(speaker_path):\n",
    "            for filename in os.listdir(speaker_path):\n",
    "                if filename.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(speaker_path, filename)\n",
    "\n",
    "                    # Read the audio file using soundfile\n",
    "                    audio_data, sample_rate = sf.read(file_path)\n",
    "\n",
    "                    # Extract features in chunks\n",
    "                    for i in range(0, len(audio_data), int(sample_rate * chunk_size)):\n",
    "                        chunk = audio_data[i:i + int(sample_rate * chunk_size)]\n",
    "                        features = extract_features(chunk, sample_rate)\n",
    "                        \n",
    "                        # Calculate padding values\n",
    "                        pad_length = max(0, max_feature_length - len(features))\n",
    "                        pad_before = pad_length // 2\n",
    "                        pad_after = pad_length - pad_before\n",
    "\n",
    "                        # Pad features\n",
    "                        features = np.pad(features, (pad_before, pad_after), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "                        yield features, speaker_folder\n",
    "\n",
    "                    # Clear variables to free up memory\n",
    "                    del audio_data\n",
    "                    del features\n",
    "\n",
    "# ...\n",
    "\n",
    "\n",
    "\n",
    "# Main program for training the model\n",
    "if __name__ == \"__main__\":\n",
    "    # Change the path to the folder where your dataset is stored\n",
    "    dataset_folder = 'audio'\n",
    "\n",
    "    # Initialize variables\n",
    "    data = []\n",
    "    labels = []\n",
    "    max_feature_length = 0\n",
    "\n",
    "    # Generate and collect data in chunks\n",
    "    data_generator = generate_data(dataset_folder)\n",
    "    for features, label in data_generator:\n",
    "        data.append(features)\n",
    "        labels.append(label)\n",
    "        max_feature_length = max(max_feature_length, len(features))\n",
    "\n",
    "    # Pad features to ensure a consistent shape\n",
    "    data = [np.pad(features, (0, max_feature_length - len(features)), mode='constant', constant_values=(0, 0)) for features in data]\n",
    "\n",
    "    # Convert data and labels to numpy arrays\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=40)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Save the trained model\n",
    "    joblib.dump(clf, 'speaker_identification_model.joblib')\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a8642f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Ajay       1.00      1.00      1.00         1\n",
      "      Hardik       0.00      0.00      0.00         3\n",
      "     Kratika       1.00      1.00      1.00         1\n",
      "      Sonali       1.00      1.00      1.00         2\n",
      "     Vedansh       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.65      0.80      0.68         8\n",
      "weighted avg       0.53      0.62      0.55         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braje\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\braje\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\braje\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Test the model\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd09e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e79af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce00ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9ec07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
